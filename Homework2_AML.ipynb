{"cells":[{"cell_type":"markdown","metadata":{"id":"qf3z5SqWZ91b"},"source":["# Torch"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36612,"status":"ok","timestamp":1700589869346,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"YbtEmI1AiTkF","outputId":"56526a77-519d-4840-f130-94170c0d6ead"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["import torch\n","\n","# use GPU if available\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  #'cpu' # 'cuda' or 'cpu'\n","print(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"czjvnq3FjBmh"},"source":["# Download Dataset GTEA61\n","For Google Colab"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147076,"status":"ok","timestamp":1700590037711,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"GBkwNEyc_09F","outputId":"453cd5e3-2eb1-4a84-9fe6-30694be199ab"},"outputs":[{"data":{"text/plain":["' \\n\\nfrom google.colab import drive\\nimport os\\ndrive.mount(\\'/content/drive\\')\\nimport sys, os\\n\\nif not os.path.isfile(\\'/content/GTEA61\\'):\\n  !unzip  \"/content/drive/MyDrive/Colab Notebooks/GTEA61.zip\" -d \"/content/\"\\n\\nif not os.path.isdir(\\'/content/GTEA61\\'):\\n  print(\"Dataset doesn\\'t exist\")\\n\\n#Weights\\nif not os.path.isfile(\"/content/best_model_state_dict_rgb_split2.pth\"):\\n  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\\n\\n'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" \n","\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","import sys, os\n","\n","if not os.path.isfile('/content/GTEA61'):\n","\n","  !unzip  \"/content/drive/MyDrive/Colab Notebooks/GTEA61.zip\" -d \"/content/\"\n","\n","if not os.path.isdir('/content/GTEA61'):\n","  print(\"Dataset doesn't exist\")\n","\n","#Weights\n","if not os.path.isfile(\"/content/best_model_state_dict_rgb_split2.pth\"):\n","  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\n","\n","  \n","# original\n","\n","import os\n","\n","#1YKfdhB9Xxh4pmND1V3gcm3Gyjc8v8idq\n","if not os.path.isfile('/content/GTEA61.zip'):\n","  !gdown --id 1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk # 3-5 min\n","  !jar xvf  \"/content/GTEA61.zip\"\n","\n","if not os.path.isdir('/content/GTEA61'):\n","  print(\"Dataset doesn't exist\")\n","\n","#Weights\n","if not os.path.isfile(\"best_model_state_dict_rgb_split2.pth\"):\n","  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"Kk0rtAlnSlDF"},"source":["\n","# Download Code"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1931,"status":"ok","timestamp":1700591839274,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"Z8xcWfReaSd_","outputId":"c025be60-cef4-479f-b4f9-277400598441"},"outputs":[{"name":"stderr","output_type":"stream","text":["'gdown' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["!git clone \"https://github.com/plana93/Homework_AIML.git\"\n"]},{"cell_type":"markdown","metadata":{"id":"jiwWzjzSio-h"},"source":["\n","\n","# Import Code\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2979,"status":"ok","timestamp":1700591844743,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"wl6fSd3MXofW"},"outputs":[],"source":["import os\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.backends import cudnn\n","from colorama import init\n","from colorama import Fore, Back, Style\n","\n","from torchvision.models import resnet34\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import sys\n","\n","sys.path.append(\"Homework_AIML/\")\n","import Homework_AIML\n","from Homework_AIML import *\n","\n","from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n","from spatial_transforms import (\n","    Compose,\n","    ToTensor,\n","    CenterCrop,\n","    Scale,\n","    Normalize,\n","    MultiScaleCornerCrop,\n","    RandomHorizontalFlip,\n",")"]},{"cell_type":"markdown","metadata":{"id":"g1GznJhObXPk"},"source":["# **Learning without Temporal information** (avgpool)"]},{"cell_type":"markdown","metadata":{"id":"Sy4KrHClbAmC"},"source":["## MAIN PARAMs"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":449,"status":"ok","timestamp":1700591851423,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"w-tz9mHPbCYW"},"outputs":[],"source":["homework_step = 0  # --> Learning without Temporal information (avgpool)\n","# homework_step = 1 #--> Learning with Temporal information (LSTM)\n","# homework_step = 2 #--> Learning with Spatio-Temporal information (ConvLSTM)\n","\n","\n","DATA_DIR = \"datasets/GTEA61/\"  # path dataset\n","model_folder = \"saved_models/\" + \"homework_step\" + str(homework_step) + \"/\"  # path to save model\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)\n","\n","\n","# All this param can be change!\n","\n","NUM_CLASSES = 61\n","BATCH_SIZE = 64\n","LR = 0.001  # The initial Learning Rate\n","MOMENTUM = 0.9  # Hyperparameter for SGD, keep this at 0.9 when using SGD\n","WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n","NUM_EPOCHS = 200  # Total number of training epochs (iterations over dataset)\n","STEP_SIZE = [25, 75, 150]  # How many epochs before decreasing learning rate (if using a step-down policy)\n","GAMMA = 0.1  # Multiplicative factor for learning rate step-down\n","MEM_SIZE = 512  # Dim of internal state of LSTM or ConvLSTM\n","SEQ_LEN = 3  # Num Frames\n","\n","# this dictionary is needed for the logger class\n","parameters = {\n","    \"DEVICE\": DEVICE,\n","    \"NUM_CLASSES\": NUM_CLASSES,\n","    \"BATCH_SIZE\": BATCH_SIZE,\n","    \"LR\": LR,\n","    \"MOMENTUM\": MOMENTUM,\n","    \"WEIGHT_DECAY\": WEIGHT_DECAY,\n","    \"NUM_EPOCHS\": NUM_EPOCHS,\n","    \"STEP_SIZE\": STEP_SIZE,\n","    \"GAMMA\": GAMMA,\n","    \"MEM_SIZE\": MEM_SIZE,\n","    \"SEQ_LEN\": SEQ_LEN,\n","}"]},{"cell_type":"markdown","metadata":{"id":"UPwkOR8taVdN"},"source":["## Dataloaders & Preprocessing"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700591853618,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"LT_Gy79SgBLq"},"outputs":[],"source":["# Normalize\n","normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","spatial_transform = Compose(\n","    [Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224), ToTensor(), normalize]\n",")\n","spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700591853618,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"T69vfGGhjKa_","outputId":"f0dba6f8-c981-4d0c-fdeb-a9bcad122e92"},"outputs":[{"name":"stdout","output_type":"stream","text":["['S1', 'S2', 'S3', 'S4']\n","['S1', 'S2', 'S3', 'S4']\n","Train Dataset: 341\n","Test Dataset: 116\n"]}],"source":["# Prepare Pytorch train/test Datasets\n","train_dataset = GTEA61(DATA_DIR, split=\"train\", transform=spatial_transform, seq_len=SEQ_LEN)\n","test_dataset = GTEA61(DATA_DIR, split=\"test\", transform=spatial_transform_val, seq_len=SEQ_LEN)\n","\n","# Check dataset sizes\n","print(\"Train Dataset: {}\".format(len(train_dataset)))\n","print(\"Test Dataset: {}\".format(len(test_dataset)))\n","\n","# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"21wjiwvW-OPQ"},"source":["## Model"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":426,"status":"ok","timestamp":1700591857243,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"XMWuE-4SHxoY"},"outputs":[],"source":["import torch\n","import resnetMod\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","\n","\n","# LSTM\n","class MyLSTMCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(MyLSTMCell, self).__init__()\n","\n","        self.linear_f = nn.Linear(input_size + hidden_size, hidden_size)\n","        self.linear_i = nn.Linear(input_size + hidden_size, hidden_size)\n","        self.linear_g = nn.Linear(input_size + hidden_size, hidden_size)\n","        self.linear_o = nn.Linear(input_size + hidden_size, hidden_size)\n","\n","    def forward(self, x, state):\n","        if state is None:\n","            state = (\n","                Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n","                Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n","            )\n","\n","        c_t1, h_t1 = state\n","        input = torch.hstack((h_t1, x))\n","        f = torch.sigmoid(self.linear_f(input))\n","        i = torch.sigmoid(self.linear_i(input))\n","        g = torch.tanh(self.linear_g(input))\n","        o = torch.sigmoid(self.linear_o(input))\n","\n","        c_t = f * c_t1 + (i * g)\n","        h_t = o * torch.tanh(c_t)\n","\n","        ##################################\n","        # You should implement this part #\n","        ##################################\n","\n","        return c_t, h_t\n","\n","\n","# ConvLSTM\n","class MyConvLSTMCell(nn.Module):\n","    def __init__(self, input_size, hidden_size, kernel_size=3, stride=1, padding=1):\n","        super(MyConvLSTMCell, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.conv_i_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_i_hh = nn.Conv2d(\n","            hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n","        )\n","\n","        self.conv_f_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_f_hh = nn.Conv2d(\n","            hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n","        )\n","\n","        self.conv_c_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_c_hh = nn.Conv2d(\n","            hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n","        )\n","\n","        self.conv_o_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_o_hh = nn.Conv2d(\n","            hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n","        )\n","\n","        torch.nn.init.xavier_normal_(self.conv_i_xx.weight)\n","        torch.nn.init.constant_(self.conv_i_xx.bias, 0)\n","        torch.nn.init.xavier_normal_(self.conv_i_hh.weight)\n","\n","        torch.nn.init.xavier_normal_(self.conv_f_xx.weight)\n","        torch.nn.init.constant_(self.conv_f_xx.bias, 0)\n","        torch.nn.init.xavier_normal_(self.conv_f_hh.weight)\n","\n","        torch.nn.init.xavier_normal_(self.conv_c_xx.weight)\n","        torch.nn.init.constant_(self.conv_c_xx.bias, 0)\n","        torch.nn.init.xavier_normal_(self.conv_c_hh.weight)\n","\n","        torch.nn.init.xavier_normal_(self.conv_o_xx.weight)\n","        torch.nn.init.constant_(self.conv_o_xx.bias, 0)\n","        torch.nn.init.xavier_normal_(self.conv_o_hh.weight)\n","\n","    def forward(self, x, state):\n","        if state is None:\n","            state = (\n","                Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n","                Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n","            )\n","\n","        c_t1, h_t1 = state\n","\n","        f = torch.sigmoid(self.conv_f_xx(x) + self.conv_f_hh(h_t1))\n","        i = torch.sigmoid(self.conv_i_xx(x) + self.conv_i_hh(h_t1))\n","        g = torch.tanh(self.conv_c_xx(x) + self.conv_c_hh(h_t1))\n","        o = torch.sigmoid(self.conv_o_xx(x) + self.conv_o_hh(h_t1))\n","\n","        c_t = f * c_t1 + (i * g)\n","        h_t = o * torch.tanh(c_t)\n","\n","        ##################################\n","        # You should implement this part #\n","        ##################################\n","\n","        return c_t, h_t\n","\n","\n","# Network\n","class ourModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512, homework_step=0, DEVICE=\"\"):\n","        super(ourModel, self).__init__()\n","        self.DEVICE = DEVICE\n","        self.num_classes = num_classes\n","        self.resNet = resnetMod.resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.homework_step = homework_step\n","        if self.homework_step == 1:\n","            self.lstm_cell = MyLSTMCell(512, mem_size)\n","        elif self.homework_step == 2:\n","            self.lstm_cell = MyConvLSTMCell(512, mem_size)\n","\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","\n","    def forward(self, inputVariable):\n","        # Learning without Temporal information (mean)\n","        if self.homework_step == 0:\n","            video_level_features = torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE)\n","            for t in range(inputVariable.size(0)):\n","                # spatial_frame_feat: (bs, 512, 7, 7)\n","                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n","                # frames_feat: (bs, 512)\n","                frame_feat = self.avgpool(spatial_frame_feat).view(spatial_frame_feat.size(0), -1)\n","                video_level_features = video_level_features + frame_feat\n","\n","            video_level_features = video_level_features / inputVariable.size(0)\n","            logits = self.classifier(video_level_features)\n","            return logits, video_level_features\n","\n","        # Learning with Temporal information (LSTM)\n","        elif self.homework_step == 1:\n","            # inputVariable = (Frames, BS, C, W, H)\n","            state = (\n","                torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),  # h_t\n","                torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),  # c_t\n","            )\n","            # for each frame (t -> tempo)\n","            for t in range(inputVariable.size(0)):\n","                # spatial_frame_feat: (bs, 512, 7, 7)\n","                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n","                # frames_feat: (bs, 512)\n","                frame_feat = self.avgpool(spatial_frame_feat).view(state[1].size(0), -1)\n","                # in this way the state t go in the cell at t + 1\n","                state = self.lstm_cell(frame_feat, state)\n","\n","            video_level_features = state[1]\n","            logits = self.classifier(video_level_features)\n","            return logits, video_level_features\n","\n","        # Learning with Temporal information (ConvLSTM)\n","        elif self.homework_step == 2:\n","            state = (\n","                torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n","                torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n","            )\n","            for t in range(inputVariable.size(0)):\n","                # spatial_frame_feat: (bs, 512, 7, 7)\n","                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n","                state = self.lstm_cell(spatial_frame_feat, state)\n","            video_level_features = self.avgpool(state[1]).view(state[1].size(0), -1)\n","            logits = self.classifier(video_level_features)\n","            return logits, video_level_features"]},{"cell_type":"markdown","metadata":{"id":"Ru8vllrMbgvL"},"source":["## Build Model - Loss - Opt"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7434,"status":"ok","timestamp":1700591872901,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"XZe-ZbEL7z3x","outputId":"20a3f7cd-72f0-45fc-895a-568058290aa5"},"outputs":[],"source":["# CUDA_LAUNCH_BLOCKING=1\n","validate = True\n","\n","model = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE)  # model\n","\n","# Train only the lstm cell and classifier\n","model.train(False)\n","for params in model.parameters():\n","    params.requires_grad = False\n","\n","if homework_step > 0:\n","    for params in model.lstm_cell.parameters():\n","        params.requires_grad = True\n","    model.lstm_cell.train(True)\n","\n","for params in model.classifier.parameters():\n","    params.requires_grad = True\n","model.classifier.train(True)\n","\n","\n","model = model.to(DEVICE)\n","\n","# model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n","\n","\n","# Loss\n","loss_fn = nn.CrossEntropyLoss()\n","# Opt\n","trainable_params = [p for p in model.parameters() if p.requires_grad]\n","optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n","# Scheduler\n","optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)"]},{"cell_type":"markdown","metadata":{"id":"z0MWgLingzhw"},"source":["## Training\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["def training(model, homework_step=0, model_checkpoint=\"model\", patience=10, save_model=False):\n","    patience_count = 0\n","    train_iter = 0\n","    val_iter = 0\n","    min_accuracy = 0\n","\n","    trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n","    val_samples = len(test_dataset)\n","\n","    iterPerEpoch = len(train_loader)\n","    val_steps = len(val_loader)\n","\n","    cudnn.benchmark\n","\n","    for epoch in range(NUM_EPOCHS):\n","        epoch_loss = 0\n","        numCorrTrain = 0\n","\n","        # blocks to train\n","        if homework_step > 0:\n","            model.lstm_cell.train(True)\n","\n","        model.classifier.train(True)\n","\n","        for i, (inputs, targets) in enumerate(train_loader):\n","            train_iter += 1\n","            optimizer_fn.zero_grad()\n","\n","            # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n","\n","            inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n","            labelVariable = targets.to(DEVICE)\n","\n","            # feeds in model\n","            output_label, _ = model(inputVariable)\n","\n","            # compute loss\n","            loss = loss_fn(output_label, labelVariable)\n","\n","            # backward loss and optimizer step\n","            loss.backward()\n","            optimizer_fn.step()\n","\n","            # compute the training accuracy\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n","            step_loss = loss.data.item()\n","\n","            epoch_loss += step_loss\n","\n","        avg_loss = epoch_loss / iterPerEpoch\n","\n","        trainAccuracy = (numCorrTrain / trainSamples) * 100\n","        # train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n","\n","        print(Fore.WHITE + f\"Train: Epoch = {epoch + 1} | Loss = {avg_loss:.3f} | Accuracy = {trainAccuracy:.3f}\")\n","        if validate:\n","            if (epoch + 1) % 1 == 0:\n","                model.train(False)\n","                val_loss_epoch = 0\n","                numCorr = 0\n","                for j, (inputs, targets) in enumerate(val_loader):\n","                    val_iter += 1\n","\n","                    inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n","                    labelVariable = targets.to(DEVICE)\n","\n","                    output_label, _ = model(inputVariable)\n","                    val_loss = loss_fn(output_label, labelVariable)\n","                    val_loss_step = val_loss.data.item()\n","\n","                    val_loss_epoch += val_loss_step\n","                    _, predicted = torch.max(output_label.data, 1)\n","                    numCorr += torch.sum(predicted == labelVariable.data).data.item()\n","\n","                    # val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n","\n","                val_accuracy = (numCorr / val_samples) * 100\n","                avg_val_loss = val_loss_epoch / val_steps\n","\n","                print(\n","                    Fore.GREEN\n","                    + \"Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}\".format(epoch + 1, avg_val_loss, val_accuracy)\n","                )\n","                if val_accuracy > min_accuracy:\n","                    print(\"[||| NEW BEST on val||||]\")\n","                    patience_count = 0\n","                    if save_model:\n","                        save_path_model = os.path.join(model_folder, model_checkpoint)\n","                        torch.save(model.state_dict(), save_path_model)\n","                    min_accuracy = val_accuracy\n","                elif val_accuracy < min_accuracy:\n","                    patience_count += 1\n","\n","            if patience_count == patience:\n","                print(Fore.RED + \"EARLY STOPPING\")\n","                break\n","\n","        optim_scheduler.step()\n","\n","    print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n","    print(Fore.CYAN + \"Last Acc --> \", val_accuracy)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[37mTrain: Epoch = 1 | Loss = 4.696 | Accuracy = 1.562\n","\u001b[32mVal: Epoch = 1 | Loss 4.032 | Accuracy = 3.448\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 2 | Loss = 4.512 | Accuracy = 3.750\n","\u001b[32mVal: Epoch = 2 | Loss 3.985 | Accuracy = 6.897\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 3 | Loss = 4.525 | Accuracy = 3.125\n","\u001b[32mVal: Epoch = 3 | Loss 3.962 | Accuracy = 9.483\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 4 | Loss = 4.238 | Accuracy = 5.000\n","\u001b[32mVal: Epoch = 4 | Loss 3.888 | Accuracy = 8.621\n","\u001b[37mTrain: Epoch = 5 | Loss = 4.333 | Accuracy = 4.375\n","\u001b[32mVal: Epoch = 5 | Loss 3.834 | Accuracy = 8.621\n","\u001b[37mTrain: Epoch = 6 | Loss = 4.233 | Accuracy = 3.438\n","\u001b[32mVal: Epoch = 6 | Loss 3.792 | Accuracy = 8.621\n","\u001b[37mTrain: Epoch = 7 | Loss = 4.199 | Accuracy = 3.125\n","\u001b[32mVal: Epoch = 7 | Loss 3.752 | Accuracy = 9.483\n","\u001b[37mTrain: Epoch = 8 | Loss = 4.119 | Accuracy = 7.812\n","\u001b[32mVal: Epoch = 8 | Loss 3.714 | Accuracy = 11.207\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 9 | Loss = 4.102 | Accuracy = 7.812\n","\u001b[32mVal: Epoch = 9 | Loss 3.679 | Accuracy = 12.931\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 10 | Loss = 4.030 | Accuracy = 8.125\n","\u001b[32mVal: Epoch = 10 | Loss 3.643 | Accuracy = 12.069\n","\u001b[37mTrain: Epoch = 11 | Loss = 3.976 | Accuracy = 9.688\n","\u001b[32mVal: Epoch = 11 | Loss 3.609 | Accuracy = 13.793\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 12 | Loss = 4.038 | Accuracy = 6.562\n","\u001b[32mVal: Epoch = 12 | Loss 3.580 | Accuracy = 15.517\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 13 | Loss = 3.900 | Accuracy = 7.187\n","\u001b[32mVal: Epoch = 13 | Loss 3.547 | Accuracy = 19.828\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 14 | Loss = 3.911 | Accuracy = 7.812\n","\u001b[32mVal: Epoch = 14 | Loss 3.513 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 15 | Loss = 4.034 | Accuracy = 5.000\n","\u001b[32mVal: Epoch = 15 | Loss 3.488 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 16 | Loss = 3.875 | Accuracy = 8.438\n","\u001b[32mVal: Epoch = 16 | Loss 3.457 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 17 | Loss = 3.835 | Accuracy = 11.562\n","\u001b[32mVal: Epoch = 17 | Loss 3.427 | Accuracy = 16.379\n","\u001b[37mTrain: Epoch = 18 | Loss = 3.725 | Accuracy = 12.500\n","\u001b[32mVal: Epoch = 18 | Loss 3.396 | Accuracy = 15.517\n","\u001b[37mTrain: Epoch = 19 | Loss = 3.754 | Accuracy = 10.625\n","\u001b[32mVal: Epoch = 19 | Loss 3.375 | Accuracy = 14.655\n","\u001b[37mTrain: Epoch = 20 | Loss = 3.805 | Accuracy = 9.062\n","\u001b[32mVal: Epoch = 20 | Loss 3.354 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 21 | Loss = 3.731 | Accuracy = 9.375\n","\u001b[32mVal: Epoch = 21 | Loss 3.336 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 22 | Loss = 3.617 | Accuracy = 15.000\n","\u001b[32mVal: Epoch = 22 | Loss 3.326 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 23 | Loss = 3.794 | Accuracy = 10.938\n","\u001b[32mVal: Epoch = 23 | Loss 3.311 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 24 | Loss = 3.535 | Accuracy = 13.438\n","\u001b[32mVal: Epoch = 24 | Loss 3.288 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 25 | Loss = 3.553 | Accuracy = 15.000\n","\u001b[32mVal: Epoch = 25 | Loss 3.260 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 26 | Loss = 3.538 | Accuracy = 15.313\n","\u001b[32mVal: Epoch = 26 | Loss 3.258 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 27 | Loss = 3.564 | Accuracy = 12.188\n","\u001b[32mVal: Epoch = 27 | Loss 3.255 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 28 | Loss = 3.635 | Accuracy = 13.125\n","\u001b[32mVal: Epoch = 28 | Loss 3.251 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 29 | Loss = 3.587 | Accuracy = 12.812\n","\u001b[32mVal: Epoch = 29 | Loss 3.247 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 30 | Loss = 3.568 | Accuracy = 14.062\n","\u001b[32mVal: Epoch = 30 | Loss 3.243 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 31 | Loss = 3.625 | Accuracy = 12.188\n","\u001b[32mVal: Epoch = 31 | Loss 3.238 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 32 | Loss = 3.572 | Accuracy = 15.000\n","\u001b[32mVal: Epoch = 32 | Loss 3.235 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 33 | Loss = 3.622 | Accuracy = 11.250\n","\u001b[32mVal: Epoch = 33 | Loss 3.232 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 34 | Loss = 3.517 | Accuracy = 15.937\n","\u001b[32mVal: Epoch = 34 | Loss 3.229 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 35 | Loss = 3.620 | Accuracy = 12.812\n","\u001b[32mVal: Epoch = 35 | Loss 3.226 | Accuracy = 18.103\n","\u001b[31mEARLY STOPPING\n","\u001b[36mBest Acc -->  19.82758620689655\n","\u001b[36mLast Acc -->  18.103448275862068\n"]}],"source":["training(model, homework_step=0, patience=20, save_model=True)"]},{"cell_type":"markdown","metadata":{"id":"lrLs_T2Qd0kc"},"source":["## Test"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["def test(model):\n","    model.train(False)\n","    val_loss_epoch = 0\n","    numCorr = 0\n","    val_iter = 0\n","    val_samples = len(test_dataset)\n","    val_steps = len(val_loader)\n","\n","    with torch.no_grad():\n","        for j, (inputs, targets) in enumerate(val_loader):\n","            val_iter += 1\n","            inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n","            labelVariable = targets.to(DEVICE)\n","\n","            output_label, _ = model(inputVariable)\n","            val_loss = loss_fn(output_label, labelVariable)\n","            val_loss_step = val_loss.data.item()\n","            val_loss_epoch += val_loss_step\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorr += torch.sum(predicted == labelVariable.data).data.item()\n","\n","        val_accuracy = (numCorr / val_samples) * 100\n","        avg_val_loss = val_loss_epoch / val_steps\n","\n","    print(\"Loss {:.3f} | Accuracy = {:.3f}\".format(avg_val_loss, val_accuracy))"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2677,"status":"ok","timestamp":1700593844058,"user":{"displayName":"Davide Vitabile","userId":"10252235014316076173"},"user_tz":-60},"id":"gqK1ExB0cl8D","outputId":"02c99f4c-9815-45a0-fcf5-0c0e921a4a9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss 3.226 | Accuracy = 18.103\n"]}],"source":["test(model)"]},{"cell_type":"markdown","metadata":{"id":"Gr9BxL8zeBfv"},"source":["# **Learning with Temporal information** (LSTM)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["homework_step = 1\n","\n","DATA_DIR = \"datasets/GTEA61/\"  # path dataset\n","model_folder = \"saved_models/\" + \"homework_step\" + str(homework_step) + \"/\"  # path to save model\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["validate = True\n","\n","model_LSTM = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE)  # model\n","\n","# Train only the lstm cell and classifier\n","model_LSTM.train(False)\n","for params in model_LSTM.parameters():\n","    params.requires_grad = False\n","\n","if homework_step > 0:\n","    for params in model_LSTM.lstm_cell.parameters():\n","        params.requires_grad = True\n","    model_LSTM.lstm_cell.train(True)\n","\n","for params in model_LSTM.classifier.parameters():\n","    params.requires_grad = True\n","model_LSTM.classifier.train(True)\n","\n","\n","model_LSTM = model_LSTM.to(DEVICE)\n","\n","# model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n","\n","\n","# Loss\n","loss_fn = nn.CrossEntropyLoss()\n","# Opt\n","trainable_params = [p for p in model_LSTM.parameters() if p.requires_grad]\n","optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n","# Scheduler\n","optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[37mTrain: Epoch = 1 | Loss = 4.154 | Accuracy = 3.125\n","\u001b[32mVal: Epoch = 1 | Loss 3.961 | Accuracy = 6.034\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 2 | Loss = 4.013 | Accuracy = 6.562\n","\u001b[32mVal: Epoch = 2 | Loss 3.918 | Accuracy = 6.034\n","\u001b[37mTrain: Epoch = 3 | Loss = 4.021 | Accuracy = 6.562\n","\u001b[32mVal: Epoch = 3 | Loss 3.898 | Accuracy = 6.034\n","\u001b[37mTrain: Epoch = 4 | Loss = 3.961 | Accuracy = 7.187\n","\u001b[32mVal: Epoch = 4 | Loss 3.869 | Accuracy = 7.759\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 5 | Loss = 3.948 | Accuracy = 5.625\n","\u001b[32mVal: Epoch = 5 | Loss 3.832 | Accuracy = 7.759\n","\u001b[37mTrain: Epoch = 6 | Loss = 3.895 | Accuracy = 6.875\n","\u001b[32mVal: Epoch = 6 | Loss 3.820 | Accuracy = 7.759\n","\u001b[37mTrain: Epoch = 7 | Loss = 3.892 | Accuracy = 7.187\n","\u001b[32mVal: Epoch = 7 | Loss 3.782 | Accuracy = 8.621\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 8 | Loss = 3.792 | Accuracy = 11.562\n","\u001b[32mVal: Epoch = 8 | Loss 3.718 | Accuracy = 7.759\n","\u001b[37mTrain: Epoch = 9 | Loss = 3.740 | Accuracy = 9.375\n","\u001b[32mVal: Epoch = 9 | Loss 3.679 | Accuracy = 10.345\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 10 | Loss = 3.716 | Accuracy = 12.812\n","\u001b[32mVal: Epoch = 10 | Loss 3.633 | Accuracy = 10.345\n","\u001b[37mTrain: Epoch = 11 | Loss = 3.688 | Accuracy = 9.062\n","\u001b[32mVal: Epoch = 11 | Loss 3.641 | Accuracy = 12.069\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 12 | Loss = 3.637 | Accuracy = 10.938\n","\u001b[32mVal: Epoch = 12 | Loss 3.580 | Accuracy = 12.931\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 13 | Loss = 3.506 | Accuracy = 13.750\n","\u001b[32mVal: Epoch = 13 | Loss 3.517 | Accuracy = 10.345\n","\u001b[37mTrain: Epoch = 14 | Loss = 3.424 | Accuracy = 14.688\n","\u001b[32mVal: Epoch = 14 | Loss 3.448 | Accuracy = 11.207\n","\u001b[37mTrain: Epoch = 15 | Loss = 3.480 | Accuracy = 13.125\n","\u001b[32mVal: Epoch = 15 | Loss 3.489 | Accuracy = 9.483\n","\u001b[37mTrain: Epoch = 16 | Loss = 3.406 | Accuracy = 15.000\n","\u001b[32mVal: Epoch = 16 | Loss 3.445 | Accuracy = 12.069\n","\u001b[37mTrain: Epoch = 17 | Loss = 3.359 | Accuracy = 15.313\n","\u001b[32mVal: Epoch = 17 | Loss 3.426 | Accuracy = 9.483\n","\u001b[37mTrain: Epoch = 18 | Loss = 3.209 | Accuracy = 16.250\n","\u001b[32mVal: Epoch = 18 | Loss 3.311 | Accuracy = 15.517\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 19 | Loss = 3.199 | Accuracy = 21.250\n","\u001b[32mVal: Epoch = 19 | Loss 3.243 | Accuracy = 18.966\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 20 | Loss = 3.134 | Accuracy = 21.562\n","\u001b[32mVal: Epoch = 20 | Loss 3.196 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 21 | Loss = 3.164 | Accuracy = 19.375\n","\u001b[32mVal: Epoch = 21 | Loss 3.124 | Accuracy = 15.517\n","\u001b[37mTrain: Epoch = 22 | Loss = 3.138 | Accuracy = 19.062\n","\u001b[32mVal: Epoch = 22 | Loss 3.179 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 23 | Loss = 3.133 | Accuracy = 20.938\n","\u001b[32mVal: Epoch = 23 | Loss 3.166 | Accuracy = 16.379\n","\u001b[37mTrain: Epoch = 24 | Loss = 3.050 | Accuracy = 23.125\n","\u001b[32mVal: Epoch = 24 | Loss 2.990 | Accuracy = 19.828\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 25 | Loss = 3.005 | Accuracy = 21.875\n","\u001b[32mVal: Epoch = 25 | Loss 3.049 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 26 | Loss = 2.973 | Accuracy = 24.375\n","\u001b[32mVal: Epoch = 26 | Loss 3.015 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 27 | Loss = 2.967 | Accuracy = 23.438\n","\u001b[32mVal: Epoch = 27 | Loss 2.999 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 28 | Loss = 2.989 | Accuracy = 16.562\n","\u001b[32mVal: Epoch = 28 | Loss 2.965 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 29 | Loss = 2.859 | Accuracy = 23.438\n","\u001b[32mVal: Epoch = 29 | Loss 2.944 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 30 | Loss = 2.917 | Accuracy = 19.062\n","\u001b[32mVal: Epoch = 30 | Loss 2.939 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 31 | Loss = 2.859 | Accuracy = 26.250\n","\u001b[32mVal: Epoch = 31 | Loss 2.965 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 32 | Loss = 2.849 | Accuracy = 26.562\n","\u001b[32mVal: Epoch = 32 | Loss 2.964 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 33 | Loss = 2.803 | Accuracy = 25.625\n","\u001b[32mVal: Epoch = 33 | Loss 2.922 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 34 | Loss = 2.822 | Accuracy = 26.562\n","\u001b[32mVal: Epoch = 34 | Loss 2.907 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 35 | Loss = 2.840 | Accuracy = 25.312\n","\u001b[32mVal: Epoch = 35 | Loss 2.922 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 36 | Loss = 2.791 | Accuracy = 25.625\n","\u001b[32mVal: Epoch = 36 | Loss 2.944 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 37 | Loss = 2.749 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 37 | Loss 2.969 | Accuracy = 15.517\n","\u001b[37mTrain: Epoch = 38 | Loss = 2.749 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 38 | Loss 2.948 | Accuracy = 17.241\n","\u001b[37mTrain: Epoch = 39 | Loss = 2.784 | Accuracy = 25.000\n","\u001b[32mVal: Epoch = 39 | Loss 2.898 | Accuracy = 20.690\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 40 | Loss = 2.747 | Accuracy = 28.750\n","\u001b[32mVal: Epoch = 40 | Loss 2.883 | Accuracy = 22.414\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 41 | Loss = 2.813 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 41 | Loss 2.910 | Accuracy = 21.552\n","\u001b[37mTrain: Epoch = 42 | Loss = 2.713 | Accuracy = 28.438\n","\u001b[32mVal: Epoch = 42 | Loss 2.944 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 43 | Loss = 2.834 | Accuracy = 25.312\n","\u001b[32mVal: Epoch = 43 | Loss 2.947 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 44 | Loss = 2.753 | Accuracy = 27.500\n","\u001b[32mVal: Epoch = 44 | Loss 2.918 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 45 | Loss = 2.743 | Accuracy = 28.125\n","\u001b[32mVal: Epoch = 45 | Loss 2.893 | Accuracy = 21.552\n","\u001b[37mTrain: Epoch = 46 | Loss = 2.728 | Accuracy = 23.750\n","\u001b[32mVal: Epoch = 46 | Loss 2.894 | Accuracy = 21.552\n","\u001b[37mTrain: Epoch = 47 | Loss = 2.764 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 47 | Loss 2.925 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 48 | Loss = 2.723 | Accuracy = 26.875\n","\u001b[32mVal: Epoch = 48 | Loss 2.945 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 49 | Loss = 2.698 | Accuracy = 27.187\n","\u001b[32mVal: Epoch = 49 | Loss 2.901 | Accuracy = 18.966\n","\u001b[37mTrain: Epoch = 50 | Loss = 2.748 | Accuracy = 27.187\n","\u001b[32mVal: Epoch = 50 | Loss 2.872 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 51 | Loss = 2.766 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 51 | Loss 2.890 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 52 | Loss = 2.708 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 52 | Loss 2.891 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 53 | Loss = 2.691 | Accuracy = 25.000\n","\u001b[32mVal: Epoch = 53 | Loss 2.885 | Accuracy = 19.828\n","\u001b[37mTrain: Epoch = 54 | Loss = 2.653 | Accuracy = 30.000\n","\u001b[32mVal: Epoch = 54 | Loss 2.869 | Accuracy = 21.552\n","\u001b[37mTrain: Epoch = 55 | Loss = 2.741 | Accuracy = 26.250\n","\u001b[32mVal: Epoch = 55 | Loss 2.869 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 56 | Loss = 2.663 | Accuracy = 27.187\n","\u001b[32mVal: Epoch = 56 | Loss 2.847 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 57 | Loss = 2.694 | Accuracy = 27.187\n","\u001b[32mVal: Epoch = 57 | Loss 2.852 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 58 | Loss = 2.665 | Accuracy = 28.438\n","\u001b[32mVal: Epoch = 58 | Loss 2.844 | Accuracy = 20.690\n","\u001b[37mTrain: Epoch = 59 | Loss = 2.727 | Accuracy = 26.562\n","\u001b[32mVal: Epoch = 59 | Loss 2.871 | Accuracy = 18.103\n","\u001b[37mTrain: Epoch = 60 | Loss = 2.593 | Accuracy = 29.063\n","\u001b[32mVal: Epoch = 60 | Loss 2.880 | Accuracy = 18.103\n","\u001b[31mEARLY STOPPING\n","\u001b[36mBest Acc -->  22.413793103448278\n","\u001b[36mLast Acc -->  18.103448275862068\n"]}],"source":["training(model_LSTM, homework_step=1, model_checkpoint='model_LSTM', patience=20, save_model=True)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss 2.880 | Accuracy = 18.103\n"]}],"source":["test(model_LSTM)"]},{"cell_type":"markdown","metadata":{"id":"s-qHYgnyf_wn"},"source":["# **Learning with Spatio-Temporal information** (ConvLSTM)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["homework_step = 2\n","\n","\n","DATA_DIR = \"datasets/GTEA61/\"  # path dataset\n","model_folder = \"saved_models/\" + \"homework_step\" + str(homework_step) + \"/\"  # path to save model\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["# CUDA_LAUNCH_BLOCKING=1\n","validate = True\n","\n","model_convLSTM = ourModel(\n","    num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE\n",")  # model\n","\n","# Train only the lstm cell and classifier\n","model_convLSTM.train(False)\n","for params in model_convLSTM.parameters():\n","    params.requires_grad = False\n","\n","if homework_step > 0:\n","    for params in model_convLSTM.lstm_cell.parameters():\n","        params.requires_grad = True\n","    model_convLSTM.lstm_cell.train(True)\n","\n","for params in model_convLSTM.classifier.parameters():\n","    params.requires_grad = True\n","model_convLSTM.classifier.train(True)\n","\n","\n","model_convLSTM = model_convLSTM.to(DEVICE)\n","\n","model_convLSTM.load_state_dict(\n","    torch.load(\"best_model_state_dict_rgb_split2.pth\", map_location=torch.device(\"cpu\")), strict=True\n",")\n","\n","\n","# Loss\n","loss_fn = nn.CrossEntropyLoss()\n","# Opt\n","trainable_params = [p for p in model_convLSTM.parameters() if p.requires_grad]\n","optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n","# Scheduler\n","optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[37mTrain: Epoch = 1 | Loss = 3.748 | Accuracy = 12.812\n","\u001b[32mVal: Epoch = 1 | Loss 3.455 | Accuracy = 17.241\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 2 | Loss = 3.492 | Accuracy = 17.500\n","\u001b[32mVal: Epoch = 2 | Loss 3.235 | Accuracy = 21.552\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 3 | Loss = 3.299 | Accuracy = 15.937\n","\u001b[32mVal: Epoch = 3 | Loss 3.099 | Accuracy = 23.276\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 4 | Loss = 3.179 | Accuracy = 20.000\n","\u001b[32mVal: Epoch = 4 | Loss 3.005 | Accuracy = 25.862\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 5 | Loss = 3.002 | Accuracy = 21.562\n","\u001b[32mVal: Epoch = 5 | Loss 2.853 | Accuracy = 28.448\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 6 | Loss = 2.946 | Accuracy = 26.875\n","\u001b[32mVal: Epoch = 6 | Loss 2.793 | Accuracy = 28.448\n","\u001b[37mTrain: Epoch = 7 | Loss = 2.857 | Accuracy = 22.188\n","\u001b[32mVal: Epoch = 7 | Loss 2.667 | Accuracy = 31.897\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 8 | Loss = 2.793 | Accuracy = 27.500\n","\u001b[32mVal: Epoch = 8 | Loss 2.700 | Accuracy = 32.759\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 9 | Loss = 2.679 | Accuracy = 27.812\n","\u001b[32mVal: Epoch = 9 | Loss 2.624 | Accuracy = 29.310\n","\u001b[37mTrain: Epoch = 10 | Loss = 2.607 | Accuracy = 31.562\n","\u001b[32mVal: Epoch = 10 | Loss 2.576 | Accuracy = 31.034\n","\u001b[37mTrain: Epoch = 11 | Loss = 2.614 | Accuracy = 25.312\n","\u001b[32mVal: Epoch = 11 | Loss 2.497 | Accuracy = 31.034\n","\u001b[37mTrain: Epoch = 12 | Loss = 2.569 | Accuracy = 29.375\n","\u001b[32mVal: Epoch = 12 | Loss 2.564 | Accuracy = 30.172\n","\u001b[37mTrain: Epoch = 13 | Loss = 2.606 | Accuracy = 28.438\n","\u001b[32mVal: Epoch = 13 | Loss 2.464 | Accuracy = 34.483\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 14 | Loss = 2.497 | Accuracy = 32.188\n","\u001b[32mVal: Epoch = 14 | Loss 2.477 | Accuracy = 33.621\n","\u001b[37mTrain: Epoch = 15 | Loss = 2.427 | Accuracy = 31.250\n","\u001b[32mVal: Epoch = 15 | Loss 2.413 | Accuracy = 34.483\n","\u001b[37mTrain: Epoch = 16 | Loss = 2.377 | Accuracy = 35.938\n","\u001b[32mVal: Epoch = 16 | Loss 2.356 | Accuracy = 40.517\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 17 | Loss = 2.454 | Accuracy = 30.625\n","\u001b[32mVal: Epoch = 17 | Loss 2.418 | Accuracy = 35.345\n","\u001b[37mTrain: Epoch = 18 | Loss = 2.302 | Accuracy = 33.438\n","\u001b[32mVal: Epoch = 18 | Loss 2.362 | Accuracy = 35.345\n","\u001b[37mTrain: Epoch = 19 | Loss = 2.241 | Accuracy = 35.938\n","\u001b[32mVal: Epoch = 19 | Loss 2.261 | Accuracy = 36.207\n","\u001b[37mTrain: Epoch = 20 | Loss = 2.231 | Accuracy = 37.500\n","\u001b[32mVal: Epoch = 20 | Loss 2.405 | Accuracy = 32.759\n","\u001b[37mTrain: Epoch = 21 | Loss = 2.128 | Accuracy = 41.250\n","\u001b[32mVal: Epoch = 21 | Loss 2.239 | Accuracy = 39.655\n","\u001b[37mTrain: Epoch = 22 | Loss = 2.150 | Accuracy = 40.938\n","\u001b[32mVal: Epoch = 22 | Loss 2.390 | Accuracy = 35.345\n","\u001b[37mTrain: Epoch = 23 | Loss = 2.194 | Accuracy = 33.750\n","\u001b[32mVal: Epoch = 23 | Loss 2.229 | Accuracy = 37.931\n","\u001b[37mTrain: Epoch = 24 | Loss = 2.161 | Accuracy = 40.312\n","\u001b[32mVal: Epoch = 24 | Loss 2.371 | Accuracy = 35.345\n","\u001b[37mTrain: Epoch = 25 | Loss = 2.165 | Accuracy = 40.000\n","\u001b[32mVal: Epoch = 25 | Loss 2.220 | Accuracy = 35.345\n","\u001b[37mTrain: Epoch = 26 | Loss = 2.066 | Accuracy = 40.625\n","\u001b[32mVal: Epoch = 26 | Loss 2.197 | Accuracy = 36.207\n","\u001b[37mTrain: Epoch = 27 | Loss = 2.095 | Accuracy = 39.375\n","\u001b[32mVal: Epoch = 27 | Loss 2.183 | Accuracy = 38.793\n","\u001b[37mTrain: Epoch = 28 | Loss = 1.924 | Accuracy = 46.562\n","\u001b[32mVal: Epoch = 28 | Loss 2.168 | Accuracy = 39.655\n","\u001b[37mTrain: Epoch = 29 | Loss = 2.016 | Accuracy = 43.125\n","\u001b[32mVal: Epoch = 29 | Loss 2.137 | Accuracy = 41.379\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 30 | Loss = 2.000 | Accuracy = 45.000\n","\u001b[32mVal: Epoch = 30 | Loss 2.123 | Accuracy = 42.241\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 31 | Loss = 1.876 | Accuracy = 48.750\n","\u001b[32mVal: Epoch = 31 | Loss 2.114 | Accuracy = 41.379\n","\u001b[37mTrain: Epoch = 32 | Loss = 1.922 | Accuracy = 43.750\n","\u001b[32mVal: Epoch = 32 | Loss 2.108 | Accuracy = 43.103\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 33 | Loss = 2.016 | Accuracy = 41.250\n","\u001b[32mVal: Epoch = 33 | Loss 2.107 | Accuracy = 42.241\n","\u001b[37mTrain: Epoch = 34 | Loss = 1.904 | Accuracy = 48.750\n","\u001b[32mVal: Epoch = 34 | Loss 2.100 | Accuracy = 42.241\n","\u001b[37mTrain: Epoch = 35 | Loss = 1.989 | Accuracy = 41.875\n","\u001b[32mVal: Epoch = 35 | Loss 2.101 | Accuracy = 42.241\n","\u001b[37mTrain: Epoch = 36 | Loss = 1.949 | Accuracy = 43.438\n","\u001b[32mVal: Epoch = 36 | Loss 2.112 | Accuracy = 44.828\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 37 | Loss = 1.872 | Accuracy = 50.000\n","\u001b[32mVal: Epoch = 37 | Loss 2.110 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 38 | Loss = 1.895 | Accuracy = 43.125\n","\u001b[32mVal: Epoch = 38 | Loss 2.089 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 39 | Loss = 1.828 | Accuracy = 52.500\n","\u001b[32mVal: Epoch = 39 | Loss 2.069 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 40 | Loss = 1.852 | Accuracy = 44.375\n","\u001b[32mVal: Epoch = 40 | Loss 2.069 | Accuracy = 43.103\n","\u001b[37mTrain: Epoch = 41 | Loss = 1.875 | Accuracy = 45.938\n","\u001b[32mVal: Epoch = 41 | Loss 2.059 | Accuracy = 45.690\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 42 | Loss = 1.818 | Accuracy = 50.000\n","\u001b[32mVal: Epoch = 42 | Loss 2.053 | Accuracy = 47.414\n","[||| NEW BEST on val||||]\n","\u001b[37mTrain: Epoch = 43 | Loss = 1.843 | Accuracy = 49.375\n","\u001b[32mVal: Epoch = 43 | Loss 2.060 | Accuracy = 45.690\n","\u001b[37mTrain: Epoch = 44 | Loss = 1.769 | Accuracy = 48.750\n","\u001b[32mVal: Epoch = 44 | Loss 2.053 | Accuracy = 45.690\n","\u001b[37mTrain: Epoch = 45 | Loss = 1.885 | Accuracy = 47.500\n","\u001b[32mVal: Epoch = 45 | Loss 2.058 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 46 | Loss = 1.848 | Accuracy = 45.625\n","\u001b[32mVal: Epoch = 46 | Loss 2.067 | Accuracy = 42.241\n","\u001b[37mTrain: Epoch = 47 | Loss = 1.807 | Accuracy = 45.938\n","\u001b[32mVal: Epoch = 47 | Loss 2.057 | Accuracy = 42.241\n","\u001b[37mTrain: Epoch = 48 | Loss = 1.888 | Accuracy = 45.312\n","\u001b[32mVal: Epoch = 48 | Loss 2.048 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 49 | Loss = 1.708 | Accuracy = 52.812\n","\u001b[32mVal: Epoch = 49 | Loss 2.038 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 50 | Loss = 1.772 | Accuracy = 51.562\n","\u001b[32mVal: Epoch = 50 | Loss 2.037 | Accuracy = 45.690\n","\u001b[37mTrain: Epoch = 51 | Loss = 1.767 | Accuracy = 51.875\n","\u001b[32mVal: Epoch = 51 | Loss 2.031 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 52 | Loss = 1.746 | Accuracy = 48.750\n","\u001b[32mVal: Epoch = 52 | Loss 2.012 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 53 | Loss = 1.814 | Accuracy = 46.875\n","\u001b[32mVal: Epoch = 53 | Loss 2.010 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 54 | Loss = 1.810 | Accuracy = 51.250\n","\u001b[32mVal: Epoch = 54 | Loss 2.014 | Accuracy = 44.828\n","\u001b[37mTrain: Epoch = 55 | Loss = 1.807 | Accuracy = 48.750\n","\u001b[32mVal: Epoch = 55 | Loss 2.029 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 56 | Loss = 1.760 | Accuracy = 52.188\n","\u001b[32mVal: Epoch = 56 | Loss 2.039 | Accuracy = 41.379\n","\u001b[37mTrain: Epoch = 57 | Loss = 1.775 | Accuracy = 51.875\n","\u001b[32mVal: Epoch = 57 | Loss 2.023 | Accuracy = 43.103\n","\u001b[37mTrain: Epoch = 58 | Loss = 1.806 | Accuracy = 46.875\n","\u001b[32mVal: Epoch = 58 | Loss 2.004 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 59 | Loss = 1.813 | Accuracy = 48.438\n","\u001b[32mVal: Epoch = 59 | Loss 1.999 | Accuracy = 43.103\n","\u001b[37mTrain: Epoch = 60 | Loss = 1.718 | Accuracy = 51.875\n","\u001b[32mVal: Epoch = 60 | Loss 2.000 | Accuracy = 43.103\n","\u001b[37mTrain: Epoch = 61 | Loss = 1.723 | Accuracy = 52.812\n","\u001b[32mVal: Epoch = 61 | Loss 2.004 | Accuracy = 43.966\n","\u001b[37mTrain: Epoch = 62 | Loss = 1.688 | Accuracy = 54.375\n","\u001b[32mVal: Epoch = 62 | Loss 2.011 | Accuracy = 43.966\n","\u001b[31mEARLY STOPPING\n","\u001b[36mBest Acc -->  47.41379310344828\n","\u001b[36mLast Acc -->  43.96551724137931\n"]}],"source":["training(model_convLSTM, homework_step=2, model_checkpoint='model_convLSTM', patience=20, save_model=True)"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss 2.011 | Accuracy = 43.966\n"]}],"source":["test(model_convLSTM)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["g1GznJhObXPk","Sy4KrHClbAmC","UPwkOR8taVdN","Ru8vllrMbgvL","Gr9BxL8zeBfv"],"gpuType":"T4","provenance":[{"file_id":"14xCV5WEXQaaaenwdqs_ynaHn8ZmvL61X","timestamp":1700588775265}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
